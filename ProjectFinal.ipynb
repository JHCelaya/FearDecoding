{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIPN 162 - Fear Decoding\n",
    "\n",
    "\n",
    "# Names\n",
    "\n",
    "- Jack Celaya\n",
    "- Sophia Lanaspa\n",
    "- Ehsun Yazdani\n",
    "\n",
    "# Abstract\n",
    "\n",
    "We will be doing option 4: re-analysis of existing data using methods discussed in class to ask a question not addressed in the original paper. In the paper, they recorded single neurons in the VP while rats got different tastants and were trained to associate saccharin (normally palatable) with a negative outcome. Over time, saccharin became aversive. By aligning neural activity with licking and looking at how firing patterns changed, they showed how VP neurons tracked palatability and learning. They used PCA to reduce data complexity and visualize how responses shifted with learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[insert here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[insert here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[insert here]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "\n",
    "- Dataset #1 \n",
    "  - Dataset Name: bf-3 Data\n",
    "  - Link to the dataset: https://doi.org/10.6080/K0HH6H8V \n",
    "  - Number of variables: Firing matrix (50, 16, 435) numpy array\n",
    "  - Description: Recordings from ventral pallidum neurons in male rats undergoing fear discrimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin working with the data, we need to import some basic libraries for later use. The data is originally stored as a MatLab file, so our goal is to convert the multi-dimensional data into a .npz file to analyze and extract the firing rate for the neurons recorded so we can begin to understand what we are working with. The .npz file will allow us to use python to do our analysis as well as be structured in a numpy 3d array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common libraries that will be used\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first is to extract and save everything as one .npz file\n",
    "# cube.mat contains the researchers compiled data in the .mat format.\n",
    "\n",
    "def load_mat_file(filepath): # use scipy to open .mat file and extract relevent data.\n",
    "    \"\"\"Load a .mat file and return the VPcube structure.\"\"\"\n",
    "    mat_contents = scipy.io.loadmat(filepath, simplify_cells=True)\n",
    "    return mat_contents['cube']\n",
    "\n",
    "def extract_all_fields(cube):\n",
    "    \"\"\"Extract all relevant fields from the VPcube MATLAB structure.\"\"\"\n",
    "    return {\n",
    "        'fire': cube.get('fire'),  # firing data (z-scored, diff, raw, etc.)\n",
    "        'cer': cube.get('cer'),    # suppression ratios\n",
    "        'poke': cube.get('poke'),  # nose poke behavior\n",
    "        'name': cube.get('name'),  # neuron/session identifiers\n",
    "        'wave': cube.get('wave'),  # waveform shape\n",
    "        'half_duration': cube.get('halfduration'),\n",
    "        'amplitude_ratio': cube.get('amplituderatio'),\n",
    "        'tag': cube.get('tag')     # tag metadata\n",
    "    }\n",
    "\n",
    "def save_to_npz(output_path, data_dict):\n",
    "    \"\"\"Save all extracted fields to a compressed .npz file.\"\"\"\n",
    "    np.savez_compressed(output_path, **data_dict)\n",
    "    return output_path\n",
    "\n",
    "# Run the extraction and save process using the uploaded file\n",
    "# if it doesnt work, mess around with the file paths.\n",
    "file_path = '/cube.mat'\n",
    "cube = load_mat_file(file_path)\n",
    "full_data = extract_all_fields(cube)\n",
    "output_file = '/FearDecoding/full_dataset.npz'\n",
    "saved_path = save_to_npz(output_file, full_data)\n",
    "\n",
    "saved_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 3 functions take the matlab file and load it. Extract the variables we are interested from the matlab file, and then convert to a .npz file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to check first that the correct data has been transfered over, and will need to index through the frame multiple times to reach the spike train data to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['CV', 'CS', 'raw', 'diff', 'z'])\n",
      "dict_keys(['s1', 'ms500', 'ms250', 'ms100'])\n"
     ]
    }
   ],
   "source": [
    "# load in the dataset\n",
    "data = np.load(\"full_dataset.npz\", allow_pickle=True)\n",
    "\n",
    "# This loads in our neuron spike tensor\n",
    "fire = data['fire']\n",
    "\n",
    "# Unwraps the real object inside\n",
    "fire_raw = fire.item()\n",
    "print(fire_raw.keys())\n",
    "\n",
    "# unrwapping zscore data from 'z'\n",
    "zscore_data = fire_raw['z'] #doesnt work so there must be more keys\n",
    "print(zscore_data.keys()) # new set of columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When searching through the different layers, the shape would not appear when printed. This was the indicator that there are more keys to search through. From the data description, it is known that the firing rate is down the zscore line of columns.\n",
    "\n",
    "The second dictionary of keys contains the miliseconds they recorded in the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['interval', 'pellet', 'itiPokeCess'])\n",
      "<class 'numpy.ndarray'>\n",
      "(50, 16, 435)\n"
     ]
    }
   ],
   "source": [
    "firing_matrix = zscore_data['ms250']\n",
    "print(type(firing_matrix))\n",
    "print(firing_matrix.keys())\n",
    "\n",
    "firing_matrix = zscore_data['ms250']['pellet']\n",
    "print(type(firing_matrix))\n",
    "print(np.shape(firing_matrix))  # should be (trials, time_bins, neurons)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Null/Missing and Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[explain here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new dataset with our variables of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[explain here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exploratory Data Analysis \n",
    "\n",
    "[explain here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[explain here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[explain here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[explain here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "[explain here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussison and Conclusion\n",
    "\n",
    "[insert here]\n",
    "\n",
    "\n",
    "# Team Contributions\n",
    "\n",
    "Jack:\n",
    "\n",
    "\n",
    "Sophia:\n",
    "\n",
    "\n",
    "Ehsun: \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
